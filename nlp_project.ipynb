{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from sklearn.cluster import KMeans\n",
    "from numbers import Number\n",
    "from pandas import DataFrame\n",
    "import sys, codecs, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autovivify_list(dict):\n",
    "  def __missing__(self, key):\n",
    "    '''Given a missing key, set initial value to an empty list'''\n",
    "    value = self[key] = []\n",
    "    return value\n",
    "\n",
    "  def __add__(self, x):\n",
    "    '''Override addition for numeric types when self is empty'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return x\n",
    "    raise ValueError\n",
    "\n",
    "  def __sub__(self, x):\n",
    "    '''Also provide subtraction method'''\n",
    "    if not self and isinstance(x, Number):\n",
    "      return -1 * x\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_vector_matrix(vector_file, n_words):\n",
    "  '''Return the vectors and labels for the first n_words in vector file'''\n",
    "  numpy_arrays = []\n",
    "  labels_array = []\n",
    "  with codecs.open(vector_file, 'r', 'utf-8') as f:\n",
    "    for c, r in enumerate(f):\n",
    "      sr = r.split()\n",
    "      labels_array.append(sr[0])\n",
    "      numpy_arrays.append( numpy.array([float(i) for i in sr[1:]]) )\n",
    "\n",
    "      if c == n_words:\n",
    "        return numpy.array( numpy_arrays ), labels_array\n",
    "\n",
    "  return numpy.array( numpy_arrays ), labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_clusters(labels_array, cluster_labels):\n",
    "  '''Return the set of words in each cluster'''\n",
    "  cluster_to_words = autovivify_list()\n",
    "  for c, i in enumerate(cluster_labels):\n",
    "    cluster_to_words[ i ].append( labels_array[c] )\n",
    "  return cluster_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=121, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vector_file = 'vectors.txt' \n",
    "n_words = int(1210) # Number of words to analyze \n",
    "reduction_factor = float(0.1) # Amount of dimension reduction {0,1}\n",
    "n_clusters = int( n_words * reduction_factor ) # Number of clusters to make\n",
    "df, labels_array = build_word_vector_matrix(input_vector_file, n_words)\n",
    "kmeans_model = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans_model.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels  = kmeans_model.labels_\n",
    "cluster_inertia   = kmeans_model.inertia_\n",
    "cluster_to_words  = find_word_clusters(labels_array, cluster_labels)\n",
    "#print(cluster_to_words)\n",
    "clusters = []\n",
    "for c in cluster_to_words:\n",
    "    #print(c)\n",
    "    #print(cluster_to_words[c])\n",
    "    clusters.append(cluster_to_words[c])\n",
    "#print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ['the', 'of', 'is', 'to', 'and', '05', 'in', 'that', 'it', 'by', 'are', 'for', 'or', 'used', 'an', 'term', 'on', 'has', 'with', 'we', 'problem']\n",
      "8      ['be', 'can']\n",
      "9      ['as', 'documents', 'objects', 'such', 'vectors', 'represented', 'well']\n",
      "14      ['this', 'example', 'using', 'then', 'same', 'would', 'calculated']\n",
      "16      ['probability', 'theory', 'prior']\n",
      "17      ['programming', 'object', 'dynamic', 'at', 'computer', 'oriented', 'science']\n",
      "19      ['which', 'way', 'form']\n",
      "21      ['vector', 'space', 'model']\n",
      "22      ['pagerank', 'page', 'links', 'other', 'pages', 'web']\n",
      "25      ['from', 'how', 'important', 'results', 'uses', 'high', 'linked', 'name', 'rank', 'sites']\n",
      "26      ['classes', 'derived', 'base', 'referred']\n",
      "27      ['h0k', 'he', 'ubx', 'hhk', 'hij', 'hijses']\n",
      "28      ['all', 'inherit', 'common']\n",
      "30      ['theorem', 'bayes']\n",
      "32      ['have', 'been', 'already']\n",
      "33      ['document', 'each', 'between', 'where', 'query', 'original']\n",
      "34      ['one', 'class']\n",
      "35      ['06', '000253817', '000438051', '000464908', '000479967', '000717298', '00152028', '41461e', '69545e', '07', 'conversely']\n",
      "36      ['inheritance', 'program', 'therefore']\n",
      "37      ['problems', 'sub', 'into']\n",
      "38      ['optimal', 'subproblems', 'solutions', 'substructure', 'overlapping']\n",
      "39      ['information', 'retrieval', 'indexing', 'rankings', 'relevancy', 'filtering', 'smart']\n",
      "40      ['probabilities', 'two']\n",
      "41      ['google', 'algorithm', 'link', 'analysis']\n",
      "42      ['also', 'known']\n",
      "43      ['number', 'value', 'its', 'importance']\n",
      "44      ['terms', 'words', 'if']\n",
      "45      ['called', 'because', 'generalization', 'sometimes']\n",
      "46      ['given', 'compute', 'often', 'posterior']\n",
      "48      ['not', 'will', 'there', 'so', 'they', 'certain', 'say', 'does']\n",
      "49      ['these', 'both', 'attributes', 'solved', 'variables', 'divided', 'beliefs', 'subclasses', 'themselves', 'poorly', 'behavior', 'chosen', 'behaviours', 'instances']\n",
      "51      ['conditional', 'marginal', 'relates']\n",
      "52      ['more', 'ancestor', 'exposed', 'those', 'adding']\n",
      "53      ['new', 'methods']\n",
      "54      ['may', 'solution', 'up', 'find', 'when', 'solve', 'could', 'need', 'you', 'overall', 'needs', 'larger']\n",
      "55      ['any', 'first', 'however', 'most', 'use', 'calculate', 'usually', 'distribution', 'system', 'useful', 'considered']\n",
      "56      ['events', 'random']\n",
      "57      ['about', 'values', 'specific', 'dimension', 'weights', 'developed', 'separate', 'corresponds']\n",
      "58      ['many', 'their', 'approach', 'according', 'others', 'determine', 'frequencies', 'subproblem', 'do', 'extend', 'needed', 'intended', 'create', 'due', 'subsets', 'try', 'access', 'add', 'manipulation']\n",
      "59      ['means', 'plan', 'action', 'finding', 'sense', 'acceptable']\n",
      "60      ['method', 'solving']\n",
      "61      ['search', 'another', 'best', 'superclass', '000820195', 'only', 'subclass', 'child', 'internet', 'little', 'actual', 'engine', 'having', 'users', '1940s', 'decisions', 'engines', 'parent', 'toolbar', 'updated', 'comparing', 'occurrence']\n",
      "62      ['was', 'keyword', 'concept', 'categorization', 'support', 'provides', 'representation', 'basic', 'formula', 'thus', 'powerful', 'valid', 'constant', 'originally', 'appears', 'computation', 'invented', 'technique']\n",
      "63      ['8i', '8w', '8q', 'time', 'o8', '8h', '8j', 'b8', '98', 'h8', '8d', '8f', '8l', '8p', 'd8', 't8', '8n', '8u', '8g', 'f8', 'x8', 'y8', 'q8', 'w8', 'z8', '7w', 'k8', '48', '7o', '7p', 'general', '79', '84', '38', '7d', '7v', '8s', '97', 'defined', 'j8', '28', '78', '7q', '8r', 'b9', '7f', '7y', '9s', 'computed', 'v7', '18', '7c', '7h', '7k', 'data', 'g9', '7b', '7u', 'allows', 'every', 'i7', 'main', 'relationship', 'what', '19', '7e', '7s', '7t', '7x', '83', '_8', 'j7', '77', '7m', '82', 'c7', 'generally', 'graph', 'ja', 'n9', 'see', 'zs', '6a', '6b', '6v', '72', '7_', '7l', 'b7', 'equal', 'factor', 'following', 'jj', 'k7', 'made', 'out', 'second', 'vote', '6e', '73', '76', '8_', '96', 'ae', 'assumptions', 'dx', 'fs', 'idea', 'lg', 'md', 'memoization', 'rd', 'seen', 'zn', '37', '4e', '5x', '67', '6i', '70', '93', 'ac', 'accurate', 'acts', 'bd', 'cx', 'd7', 'df', 'fi', 'formed', 'fu', 'g6', 'ii', 'il', 'iv', 'j6', 'jm', 'lt']\n",
      "64      ['different', 'non', 'order', 'ways', 'vocabulary', 'zero', 'several', 'occurs', 'appear', 'lost', 'occurring']\n",
      "65      ['8x', '9j', '8y', '9e', '9p', '9w', '9l', '9m', 'g8', '9h', 'h9', '9k', '80', 'o9', '000226815', '000818812', '00147324', '9q', '9u', 'j9', 'since', 'x9', '9c', 'trousers', '9d', 'x7', '92', '95', 'apples', 'central', '29', '49', 'dp', 'y9', '39', '7j', 'entities', 'plays', '75', 'i9', 'positive', 'simple', 'bayesians', 'rq', 'schedule', 'ff', 'finalized', 'polymorphism', 'processing', 'qx', 'view', 'ba', 'equation', 'matches', 'mechanism', 'numeric', 'our', 'rh', 'ru', 'wear', 'whole', 'yn', '1g', '60', 'co', 'debates', 'dual', 'engineering', 'entity', 'fd', 'frequentists', 'get', 'gi', 'long', 'nq', 'patented']\n",
      "66      ['code', 'set', 'interpretations', 'world', 'wide', 'relative', 'around', 'debate', 'definition', 'complexity', 'frequency', 'hyperlinked', 'measuring', 'reducing', 'foundations', 'inbound', 'purpose', 'total', 'distinct', 'angles']\n",
      "67      ['student', 'event', 'tf', 'represent', 'diagnosis', 'idf', 'case', 'correct', 'proposed', 'relationships', 'schemes', 'popularity', 'wearing', 'design', 'formal', 'happened']\n",
      "68      ['8e', '8v', '8z', '8b', 'l8', 'c8', 'p8', '8m', 's8', '9t', 'i8', 'r8', '8k', '8o', '8t', 'a8', '88', '8a', '9g', 'm8', '89', 'n8', 'u8', '9i', '9y', '87', 'v8', '9b', 'c9', 'u9', 'q9', 'r7', 'v9', 'w7', '7a', '7r', '9o', 'p9', '58', '68', '7z', '81', '8c', 'a9', 'describe', '85', '9r', 'e8', 'e9', 'f7', 'l9', 'y7', '7g', '7i', '86', '9a', 'characteristics', 'd9', 'f9', 'ir', 'l7', '09', '6m', '9_', 'k9', 'm7', 'm9', 'q7', 'r9', '08', '10', '69', '90', 'a1', 'a7', 'available', 'g7', 'h7', 'key', 'pr', 's9', 'u7', 'unique', 'z7', 'z9', '59', '7n', '91', 'e7', 'hence', 'include', 'n7', 'om', 'queries', 'relevance', 'relevant', 'systems', 'uh', 'w9', 'whilst', 'xp', 'yo', 'basically', 'bw', 'calculating', 'field', 'hg', 'ht', 'kw', 'ny', 'popular', 'postgraduate', 'qw', 'ra', 'research', 'rj', 'ro', 'solves', 'ss', 'transport', 'very', 'who', 'yz', 'z6', '17', '6l', '6r', '74', '_9', 'animals', 'bm', 'ch', 'content', 'counts', 'd6', 'da', 'dc', 'eh', 'es', 'evidence', 'features', 'fj', 'fk', 'four', 'functions', 'further', 'fv', 'gb', 'gr', 'greater', 'h1', 'h6', 'happening', 'hc', 'inherited', 'io', 'just', 'jz', 'kf', 'km', 'ku', 'kx', 'language', 'make', 'measure', 'modification', 'mt', 'nodes', 'normally', 'og', 'pp']\n",
      "69      ['being', 'fruit', 'instance', 'hierarchy', 'kind', 'models', 'element', 'identifiers', 'exhibition', 'index', 'produced', 'topic', 'girl', 'possible', 'abstraction', 'container', 'expressed', 'fleshy', 'populations', 'chance']\n",
      "70      ['no', 'particular', 'connection']\n",
      "71      ['word', 'optimization', 'mathematical', 'false', 'instead', 'result', 'languages', 'describes', 'applications', 'negative', 'might', 'synonym', 'mathematics', 'recursive']\n",
      "72      ['9x', '9n', '9f', '9v', 'similar', '99', '9z', '2099e', 'apple', 'share', 't9', 'numerical', 'orange', 'etc', 'step', 'three', 'lot', 'de', 'interfaces', 'modules', 'sufficiently', 'below', 'context', 'described', 'pieces']\n",
      "73      ['properties', 'process', 'structure', '00141866', '00142988', 'collection', 'advantage', 'exhibit', 'degrees', 'types', 'seed', 'uncertainty']\n",
      "74      ['but', 'some', 'assigned', 'assigns', 'observed', 'should', 'assign', 'applied', 'observations', 'patient', 're', 'symptoms', 'won', 'associated', 'even', 'relation', 'save', 'stored', 'cannot', 'consider', 'found', 'group', 'again', 'cases']\n",
      "75      ['computing', 'existing', 'similarity', 'naive', 'reuse', 'take', 'hijubx', 'account', 'cognitive', 'f4', 'help', 'product', 'train', 'f5', 'large', 'naturally', 'poor', 'pre', 'references', 'small', 'smaller']\n",
      "76      ['bayesian', 'based', 'depends', 'like', 'within', 'ranking', 'application', 'cosine', 'dimensionality', 'similarities', 'upon', 'scale', 'students', 'webpage', 'angle', 'specified', 'articles', 'givenis']\n",
      "77      ['keywords', 'single', 'longer', 'phrases', 'over']\n",
      "78      ['000222005', '000149611', '000208043', '000254484', '00028446', '000342545', '000388528', '000486314', '000782035', '000784815', '000908618', '000918943', '000972417', '00120731', '00130591', '00134052', '00135353', '00148554', '00154554', '0015764', '00159165', '0122e', '1804e', '28277e', '63164e', '74935e', '77299e', '7908e', '79304e', '000295394']\n",
      "79      ['000714138', '000679629', '00102065', '00130641', '00133258', '00139828', '00166282']\n",
      "80      ['000837489', '000592722', '00076664', '00078398', '00154063', '00165102']\n",
      "81      ['00105573', '000218071', '000346468', '000722866', '00118384', '00122644', '98124e']\n",
      "82      ['00127245', '00027091', '000641772', '000750848', '00127034']\n",
      "83      ['than', 'less', 'match', 'f2', 'frequentist', 'bottom', 'much', 'takes', 'down', 'f3', 'role', 'statistics', 'university', 'top', 'disagree', 'must', 'economy', 'involves', 'precisely', 'reciprocal', 'car', 'discuss', 'f1', 'mango']\n",
      "84      ['weighting', 'path', 'site', 'bellman', 'patent', 'higher', 'your', 'algorithms', 'factors', 'meaning', 'until', 'clicking', 'comes', 'goal', 'person', 'prob', 'shortest', 'stanford', 'visits', 'circle', 'denotes', 'had', 'randomly', 'among', 'outbound', 'website', 'affect', 'influence', 'modern']\n",
      "85      ['000104496', '00134634', '0015882']\n",
      "86      ['000112297', '000521099', '000851915', '00113677', '00120606', '00129875']\n",
      "87      ['000118776', '0002997', '000379887', '000767073', '00144738']\n",
      "88      ['000121415', '000251048', '000289281', '000419433', '000741238', '00121285', '00127489']\n",
      "89      ['000121931', '000154344', '000257429', '000597976', '000624961', '000769519', '000873691', '000948308', '00132224', '0014425', '00149124', '0015844']\n",
      "90      ['000128402', '000555889', '000658771', '000935097', '000997195', '00146592', '00159539']\n",
      "91      ['000146166', '000228113', '000373652', '000392118', '000822361', '000914112', '00160403']\n",
      "92      ['000154858', '000658096', '000740185', '00122127', '00143611', '00158507']\n",
      "93      ['000173975', '000434826', '000828879', '000894328', '000997342', '00134573', '00138859', '00147126', '00149773']\n",
      "94      ['000176249', '000344981', '000664931', '00067521', '00104599', '0011547']\n",
      "95      ['000204662', '000510361', '000970411', '00112897', '00132652', '00162791']\n",
      "96      ['000209893', '00038978', '000468307', '000606068', '000927189', '00110873', '00123337', '00137624', '00147916', '00159927']\n",
      "97      ['000213784', '000228605', '00044146', '000507011', '00132182']\n",
      "98      ['000218611', '000404928', '000407494', '000627347', '000654478', '000681381', '00106799', '00111769', '00142694', '00156054']\n",
      "99      ['000230336', '000309389', '0010244', '00116003', '00125393']\n",
      "100      ['000233216', '000237438', '000247751', '000302909', '000510669', '000672392', '00121509']\n",
      "101      ['000233989', '000454297', '000568793', '000615239', '000965391', '00123691']\n",
      "102      ['00024084', '000253858', '000306806', '000923061', '00150916']\n",
      "103      ['000253155', '000437583', '000558035', '00060477', '00101139', '00106998', '00112648', '001343', '00143099']\n",
      "104      ['000281587', '000392922', '000689932', '000692842', '000723977', '000797545', '000863904', '00109647', '00116315', '00124763', '00126601', '00133235', '00153604', '00153979']\n",
      "105      ['00028579', '000606723', '000641574', '000679533', '00127091', '00145284']\n",
      "106      ['000288034', '000727566', '00095051', '00145348']\n",
      "107      ['000288376', '000349485', '00070198', '000721091', '00105603', '00122734', '0015892', '00159964']\n",
      "108      ['00029439', '000388454', '000599943', '00110349']\n",
      "109      ['000339263', '00062685', '000798503', '000967188', '00104602', '00148124']\n",
      "110      ['000354644', '000393385', '000533912', '000661417', '000699741', '00160269']\n",
      "111      ['000385199', '000515494', '000920251', '000978992', '00100001', '00112502', '00116851', '00122709', '00160493']\n",
      "112      ['000429939', '00075486', '000993489', '00104788', '00124217', '00150931']\n",
      "113      ['000466403', '00118882', '00127242', '00148223']\n",
      "114      ['00046674', '000766635', '00109457', '00118601', '00162762']\n",
      "115      ['000481291', '00053947', '000884418', '000955627', '00103384', '00107373', '00121033', '00125502', '00146811', '00153857', '0669e']\n",
      "116      ['000509222', '000566388', '00117286', '00143176', '0016061', '0016119', '00162254']\n",
      "117      ['000543594', '000788925', '000861262', '000943677', '0009751', '00158112', '00159783', '00163446']\n",
      "118      ['after', 'thomas', 'law', 'rev']\n",
      "119      ['either', 'them', 'typically', 'accomplished', 'control', 'dividing', 'overriding', 'learning', 'richard', 'shared', 'controlled', 'human', 'replacing', '1953']\n",
      "120      ['representing', 'text', 'algebraic']\n"
     ]
    }
   ],
   "source": [
    "clust_dict = {}\n",
    "#print(clusters)\n",
    "for clus in clusters:\n",
    "    if len(clus) == 1:\n",
    "        if 0 not in clust_dict:\n",
    "            clust_dict[0] = clus\n",
    "        else:\n",
    "            clust_dict[0] += clus\n",
    "    else:\n",
    "        clust_dict[clusters.index(clus)] = clus\n",
    "for key, value in clust_dict.items():\n",
    "    print(key, '    ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, nltk, re\n",
    "\n",
    "# Open a file\n",
    "path = \"DATA-NLP\"\n",
    "dirs = os.listdir( path )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_mapping = dict() # Mapping to question dictionary\n",
    " # Mapping to student as key and answer as value\n",
    "\n",
    "for file in dirs:\n",
    "    if file == '.DS_Store':\n",
    "            continue\n",
    "    path_to_file=path+'/'\n",
    "    file_name = file\n",
    "    split_name = file.split('_')\n",
    "    student_name = split_name[0]\n",
    "    question_number = split_name[1].split('.')[0]\n",
    "    if question_number not in question_mapping:\n",
    "        question_mapping[question_number] = {}\n",
    "    path_to_file += file_name\n",
    "    with open(path_to_file, 'r', encoding = 'latin1') as f:\n",
    "        mylist = f.read()\n",
    "        sent_tokenize_list = nltk.sent_tokenize(mylist)\n",
    "        temp = []\n",
    "        for i in sent_tokenize_list:\n",
    "            sent = i.lower()\n",
    "            sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "            temp.append(sent)\n",
    "        question_mapping[question_number][student_name] = temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taska      {'g0pA': [[36, 0, 62, 62, 0, 17, 17, 17, 33, 0, 62, 63, 0, 0, 58, 53, 26, 0, 58, 0, 75, 26], [14, 0, 0, 0, 53, 26, 0, 75, 0, 53, 0, 49, 0, 0, 75, 26, 0, 53, 53, 0, 26, 0, 0, 0, 53, 34], [36, 69, 0, 0, 69, 0, 63, 33, 65, 0, 9, 0, 14, 0, 0, 49, 0, 67], [14, 69, 0, 63, 8, 8, 9, 73, 33, 67, 14, 8, 0, 52, 63, 0, 49, 68, 0, 14, 8, 52, 0, 0, 67, 0, 0, 61, 68], [0, 14, 63, 67, 14, 8, 42, 9, 0, 61, 0, 61, 34, 68, 14, 8, 42, 9, 0, 61, 0, 61, 34, 45, 0, 68, 34, 0, 67, 34], [36, 8, 0, 64, 33, 44, 14, 54, 73], [0, 14, 0, 54, 68, 58, 0, 68, 0, 52, 40, 26, 0, 0, 45, 67, 0, 67, 9, 49, 49, 73, 0, 67, 0, 0, 68, 67], [14, 14, 0, 49, 0, 67, 0, 67, 26, 14, 28, 53, 0, 49, 25, 49, 0, 68, 0, 67, 26]], 'g0pB': [[36, 0, 62, 62, 0, 17, 17, 17], [0, 69, 0, 75, 0, 75, 34, 66, 0, 53, 26, 0, 0, 69, 0, 63], [0, 14, 0, 69, 0, 0, 0, 69, 0], [49, 0, 48, 28, 48, 68, 25, 74, 42, 32, 58, 68, 54, 32, 43, 0, 0, 48, 32, 43, 0], [55, 49, 68, 0, 28, 73, 0], [0, 14, 14, 0, 14, 8, 55, 0, 61, 0, 63, 68, 0, 22, 9, 0, 28, 0, 0, 0, 0, 49, 49, 48, 0, 57, 73, 0, 0, 68, 0, 0, 61], [63, 17, 36], [54, 34, 34, 25, 61, 34, 28, 0, 49, 0, 53, 0, 68, 0, 0, 61], [34, 34, 84, 0, 14, 14, 0, 84, 34, 0, 61, 0, 0, 34], [0, 34, 62, 60, 19, 48, 8, 68, 0, 0, 84, 34, 0, 22, 49, 0], [55, 0, 9, 63, 0, 0, 34, 48, 48, 8, 68, 0, 58, 0, 0, 84, 34, 45, 0, 0, 48, 68], [0, 84, 34, 0, 34, 19, 59, 0, 0, 68, 0, 0, 84, 34, 0, 28, 49, 0, 84, 74, 0, 68, 0, 0, 61]], 'g0pC': [[36, 0, 17, 17, 17, 0, 33, 53, 34, 0, 63, 14, 26, 19, 32, 32, 63], [49, 26, 32, 32, 74, 0, 0, 49, 0, 49, 19, 33, 0, 0, 26, 0, 0, 68, 25], [0, 0, 36, 0, 17, 17, 17, 0, 0, 0, 75, 0, 75, 66, 68], [36, 26, 0, 8, 0, 0, 19], [0, 42, 62, 19, 0, 0, 0, 0, 63, 33, 26], [0, 14, 0, 45, 0, 48, 0], [26, 0, 14, 19, 63, 0, 49, 0, 49, 19, 0, 0, 28, 68, 0, 34, 34, 48, 14, 0, 28, 68], [0, 73, 0, 36, 0, 0, 26, 19, 14, 32, 0, 72, 66, 8, 71, 0, 14, 66, 62, 66, 0, 66, 0, 0, 36], [36, 36, 8, 42, 8, 0, 9, 65, 19, 0, 33, 58, 72, 0, 66, 0, 0, 119, 119, 66], [36, 8, 8, 119, 0, 119, 53, 0, 43, 52, 0, 0, 52, 53, 53]], 'g0pD': [[36, 0, 17, 17, 17, 0, 19, 0, 19, 53, 26, 14, 26, 0, 32, 32, 32, 63], [0, 53, 26, 42, 9, 26, 26, 28, 49, 0, 0, 0, 75, 26, 19, 0, 26, 0, 9, 26, 26], [0, 61, 0, 70, 68, 0, 0, 58, 0, 75, 75, 75, 66], [0, 0, 119, 119, 119, 0, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 52, 53, 53, 0, 52, 52, 0, 0, 52, 36, 0, 42, 45, 45, 45, 45, 48, 0, 67, 67, 69, 33, 26, 0, 9], [69, 0, 69, 0, 45, 0, 72, 83, 65, 0, 58, 58], [34, 8, 74, 69, 0, 8, 0, 69, 0, 72, 72, 72], [65, 65, 0, 69, 0, 72, 0, 69, 35, 65, 54, 75, 28, 28, 0, 73, 28, 0, 28, 69, 9, 9, 69, 69, 69, 0, 0, 73, 0], [0, 73, 0, 36, 0, 0, 72, 0, 72, 72, 72, 8, 72, 72, 0, 66, 66, 0, 66, 0, 0, 36]], 'g0pE': [[0, 17, 17, 17, 36, 0, 19, 0, 19, 53, 26, 49, 0, 19, 0, 45, 9, 14, 26, 0, 32, 32, 32, 63], [0, 36, 62, 62, 62, 0, 0], [0, 53, 26, 42, 9, 26, 26, 75, 77, 0, 28, 0, 0, 0, 75, 75, 26, 19, 0, 26, 0, 9, 26, 26, 0, 52, 26], [0, 0, 58, 0, 75, 75, 75, 66, 0, 61, 0, 70, 68], [36, 62, 0, 62, 0, 62, 0, 62, 0, 17, 71], [62, 0, 62, 65, 43, 0, 39, 65, 0, 119, 119, 0, 59, 0, 45, 63, 0, 42, 57, 57, 65, 0, 74, 0, 74, 46, 74, 8, 8, 0, 75, 83, 83, 39, 54, 0, 8, 74, 57, 33, 57, 65, 61, 43], [36, 0, 42, 45, 45, 45, 45, 0, 0, 67, 67, 69, 33, 26, 0, 9], [0, 69, 69, 0, 45, 0, 72, 72, 83, 0, 58, 58], [34, 8, 74, 69, 0, 8, 0, 69, 0, 72, 72, 72], [35, 65, 65, 0, 69, 0, 72, 0, 69, 65, 54, 75, 28, 28, 0, 73, 28, 0, 28, 69, 9, 9, 69, 69, 69, 0, 0, 73, 0], [0, 73, 0, 36, 0, 0, 72, 0, 72, 72, 72, 8, 72, 72, 0, 66, 66, 0, 66, 0, 0, 36], [36, 36, 0, 61, 65, 65, 45, 65, 19, 71, 58, 72, 0, 66, 69, 119, 0, 119, 119, 66], [36, 0, 119, 119, 119, 0, 119, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 52, 53, 53, 0, 52, 52, 0, 0, 52]], 'g1pA': [[0, 17, 17, 17, 9, 0, 37, 26, 58, 0, 58, 73, 0, 0, 68, 0, 8, 8, 0, 119], [36, 0, 73, 0, 17, 17, 17, 0, 19, 9, 0, 28, 0, 73, 0, 9, 0, 61, 34], [0, 0, 36, 0, 0, 58, 67, 33, 34, 17, 0, 61], [33, 34, 9, 0, 72, 0, 72, 73], [53, 26, 8, 8, 63, 0, 14, 73, 9, 48, 32, 73, 0, 49, 0, 26, 25, 19, 14, 53, 34, 0, 63], [61, 0, 28, 0, 0, 73, 0, 0, 49, 72, 0], [17, 0, 14, 63, 49, 0, 33, 25, 33, 22, 74, 0, 61], [49, 0, 0, 58], [58, 0, 49, 67, 17, 17, 0, 8, 0, 65, 48, 58, 48, 54, 0, 8, 54, 53, 17, 0, 64, 73, 0], [71, 53, 17, 0, 63, 0, 28, 73, 0, 9, 19, 32], [36, 8, 8, 49, 37, 40, 63, 77, 36, 0, 36], [77, 36, 59, 0, 0, 34, 8, 61, 28, 25, 34, 22, 34, 36, 63, 0, 36, 25, 64, 26]], 'g1pB': [[36, 0, 34, 0, 0, 62, 0, 17, 17, 17], [0, 0, 0, 58, 52, 0, 75, 75, 26, 68, 0, 53, 0, 49, 0, 49, 26, 0, 8], [0, 19, 0, 17, 36, 0, 9, 0, 0, 69, 0, 63], [0, 14, 0, 69, 0, 0, 0, 28, 73, 0], [0, 68, 83, 0, 36, 54, 65, 0, 52, 57, 0, 26], [0, 14, 14, 8], [63, 37, 40, 0, 64], [33, 0, 49, 8, 14, 8, 37, 49, 37, 52], [0, 14, 8, 8, 37, 0, 58, 52], [64, 0, 14, 19, 37, 22, 9, 9, 72], [0, 8, 8, 37, 49, 37, 63, 76, 0, 0, 0, 66, 0, 48, 0]], 'g1pD': [[36, 0, 60, 0, 53, 26, 14, 26], [0, 53, 26, 0, 45, 26, 26, 0, 48, 28, 0, 49, 0, 49, 0, 0, 26, 26], [0, 62, 58, 0, 75, 66, 0, 8, 0, 74, 0, 0, 70], [0, 42, 62, 0, 62, 0, 62, 0, 17, 71, 14, 0, 62, 65, 0, 39, 65, 0, 119, 119, 0, 59, 0, 45, 0, 75, 83], [36, 0, 26, 0, 9, 45, 58, 0, 0, 0, 0, 67, 67, 69, 33, 26, 0, 9], [36, 0, 0, 73, 0, 66, 0, 66, 0, 36, 65, 72, 0, 68, 72, 72, 8, 72, 0, 66], [58, 0, 14, 36, 0, 61, 65, 45, 65, 33, 58, 0, 66, 0, 69, 119, 0, 74, 119, 119, 66], [36, 0, 68, 0, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 53, 53, 0, 83, 0, 52, 52, 0, 0, 52], [36, 0, 0, 25], [33, 64, 55, 0, 64, 73, 0, 14, 0, 0, 9, 73, 0, 0, 17, 36, 69, 73, 0, 65, 73, 0, 36], [0, 0, 0, 33, 49, 25, 9, 0, 0, 48, 25, 72]], 'g2pA': [[36, 63, 57, 0, 0, 17, 68, 0, 75, 66, 61, 0, 76, 0, 36], [0, 14, 0, 0, 0, 0, 76, 57, 0, 0, 36], [0, 14, 36, 54, 0, 21, 64, 0, 68], [17, 55, 83, 0, 75, 54, 48, 32, 83, 0, 28], [74, 49, 48, 32, 17, 19, 48, 0, 0], [53, 14, 63, 8, 8, 76, 25, 54, 0, 0, 36, 69, 0, 14, 0, 34], [0, 14, 54, 54, 32, 60, 19, 63, 0, 53, 0, 75, 118, 0], [54, 71, 0, 8, 0, 54, 63, 0, 14, 39, 0, 0, 17, 0, 0, 83], [36, 59, 0, 44, 9, 60, 62, 63, 0, 0, 61, 0, 0, 75, 0, 83, 26, 55, 83, 0, 75, 17, 8, 0], [0, 75, 0, 83, 49, 0, 0, 0, 68, 34, 9, 48, 48, 32, 68, 19, 48, 72], [], [14, 8, 34, 0, 49, 83, 0, 75, 74, 32, 64, 57, 0, 75, 54, 32, 53, 0, 0], [44, 54, 14, 0, 58, 0, 68, 9, 9, 0, 54, 54, 0, 0, 42, 0, 32], [14, 54, 54, 32, 0, 69, 33, 68, 34, 0, 68, 34], [19, 32, 75, 0, 19, 14, 28, 68, 25, 49, 26]], 'g2pB': [[36, 0, 0, 25, 0, 17, 17], [14, 0, 45, 0, 63, 53, 26, 0, 8, 63, 0, 58, 26, 0, 0, 37, 52], [14, 0, 63, 0, 0, 53, 34, 0, 75, 0, 75, 34, 53, 0, 49, 68, 42, 34, 57, 53, 0, 49], [14, 59, 0, 0, 53, 34, 0, 61, 0, 52, 0, 0, 33, 0, 61], [45, 0, 14, 0, 59, 0, 0, 61, 8, 55, 28, 0, 53, 0, 49, 25, 0, 61, 55, 55, 53, 0, 49, 0], [42, 0, 74, 8, 0, 34, 8, 61, 58, 34, 34], [8, 61, 8, 61, 0, 34, 61], [55, 61, 8, 32, 52, 14, 34, 61, 0, 34, 8, 49, 8, 61, 0, 61], [44, 14, 64, 14, 28, 0, 0, 64, 53, 0, 49, 8, 8, 0, 0, 0, 55, 34], [14, 59, 0, 36, 0, 0, 54, 73, 32, 28, 84, 0, 49, 14, 8, 37, 0, 61], [14, 0, 61, 68, 14, 58, 49, 0, 58, 52], [0, 14, 0, 14, 54, 8, 14, 61, 0, 0, 14, 0, 32, 40, 49, 45, 0, 63], [9, 54, 32, 25, 0, 22, 68, 63, 54, 68, 32, 0, 63, 54, 63, 0, 25, 63, 9, 0, 63, 0, 54, 49]], 'g2pC': [[36, 0, 19, 0, 19, 53, 26, 49, 0, 19, 0, 45, 9, 14, 26, 0, 32, 32, 32, 63], [0, 53, 26, 42, 9, 26, 26, 75, 77, 0, 28, 49, 0, 49, 0, 0, 75, 75, 26, 19, 0, 26, 0, 9, 26, 26, 0, 52, 26], [0, 0, 58, 0, 75, 75, 75, 66, 0, 61, 0, 70, 68], [0, 73, 0, 36, 0, 0, 72, 0, 72, 72, 72, 8, 72, 72, 0, 66, 66, 0, 66, 0, 0, 36], [36, 36, 0, 61, 65, 65, 45, 65, 19, 71, 58, 72, 0, 66, 69, 119, 0, 119, 119, 66], [36, 0, 119, 119, 119, 0, 119, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 52, 53, 53, 0, 52, 52, 0, 0, 52], [0, 14, 36, 69, 0, 32, 32, 63, 48, 48, 28, 0, 19, 0], [14, 77, 36, 61, 8, 28, 25, 61, 34, 61], [66, 0, 58, 0, 0, 17, 0, 63, 0, 58, 0, 28, 0, 17, 61, 63], [0, 36, 69, 0, 0, 17, 0, 17, 54, 0, 17, 0, 0, 48, 48, 0, 63]], 'g2pE': [[54, 0, 57, 36, 0, 17, 17, 17, 71, 19, 0, 62, 0, 62, 62, 0, 0, 0, 0, 55, 57, 19, 0, 19, 53, 26, 0, 26, 0, 49, 0, 19, 0, 45, 9, 0, 14, 26, 0, 32, 32, 32, 63], [26, 26, 0, 58, 0, 75, 75, 75, 66, 0, 61, 0, 70, 68, 0, 0, 0, 53, 26, 0, 75, 77, 0, 28, 49, 0, 49, 0, 0, 75, 75, 26, 55, 26, 0, 9, 26, 26, 0, 52, 26], [62, 0, 17, 71, 0, 62, 19, 43, 0, 65, 39, 0, 36, 62, 0, 62, 0, 62, 0, 62], [0, 0, 0, 0, 59, 0, 45, 0, 63, 0, 42, 57, 57, 65, 0, 74, 0, 74, 46, 74, 8, 8, 0, 75, 65, 19, 83, 83, 39, 69, 0, 8, 74, 57, 33, 57, 65, 74, 0, 61, 61, 43], [0, 69, 0, 69, 0, 45, 0, 72, 72, 83, 0, 58, 58], [36, 8, 42, 45, 8, 26, 0, 9, 45, 45, 0, 67, 67, 69, 26, 0, 9], [0, 8, 8, 55, 0, 69, 0, 0, 69, 0, 72, 72, 72], [35, 65, 65, 0, 69, 48, 54, 75, 28, 28, 0, 73, 28, 0, 28, 69, 9, 9, 69, 69, 69, 0, 0, 73, 0], [72, 0, 72, 76, 0, 72, 14, 8, 0, 72, 72, 0, 66, 0, 36, 66, 0, 66, 0, 0, 36], [14, 8, 8, 42, 9, 34, 0, 0, 0, 36], [36, 36, 8, 8, 42, 0, 32, 68, 65, 65, 19, 71, 58, 0, 66, 0, 0, 119, 0, 119, 119, 66, 9, 65], [0, 0, 22, 36, 0, 68, 119, 119, 0, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 52, 53, 53, 0, 52, 52, 0, 0, 52], [9, 42, 0, 0, 0, 14, 119, 0, 45, 119]], 'g3pA': [[0, 17, 17, 17, 36, 0, 0, 0, 34, 34, 0, 8, 61, 0, 61, 14, 0, 69, 0, 26, 0, 0, 61, 26, 0, 0, 45, 52, 0, 0, 0, 63, 0, 0, 61, 26], [0, 69, 0, 0, 63, 0, 42, 55, 0, 0, 0, 26, 0, 9, 9, 0, 63, 33, 0, 61, 0, 0, 61, 0, 61, 34, 0, 69, 0, 0, 61, 34], [36, 0, 55, 0, 33, 64, 26, 72, 28, 68, 9, 9, 58, 68, 0, 63, 49], [0, 0, 14, 61, 26, 8, 8, 0, 44, 0, 58, 61, 26, 19, 8, 8, 55, 54, 75, 63, 0, 9, 0, 64, 26, 19, 8, 28, 8, 9, 34, 26, 34], [36, 0, 0, 17, 17, 17, 0, 0, 68, 0, 74, 19, 0, 61, 0, 55, 44, 48, 28, 17, 17, 71, 68], [55, 0, 49, 71, 0, 58, 62, 19, 0, 0, 0, 61, 61], [42, 0, 68, 0, 63, 49, 0, 0, 68, 0, 0, 49, 8, 8, 119, 0, 55, 0]], 'g3pB': [[36, 0, 62, 0, 17, 17, 17, 33, 61, 0, 37, 34, 68, 25, 61, 0, 34], [0, 62, 83, 43, 25, 25, 36, 33, 61, 8, 28, 68, 25, 43], [36, 17, 43, 63, 0, 21, 63, 33, 34, 17, 0, 69, 0, 61], [0, 69, 40, 26, 34, 120, 0, 67, 0, 61, 120, 67, 54, 49, 8, 0, 0, 52, 34, 120, 28, 76], [0, 54, 48, 0, 0, 0, 40, 0, 0, 0, 0, 0, 40, 73, 0, 63, 73], [49, 0, 0, 58, 0, 58], [49, 49, 0, 49, 68, 0, 0, 28, 33, 26, 8, 8, 0, 0, 66, 0, 0, 61, 0, 61, 61, 0, 49, 0, 49, 0, 0, 68, 0, 0, 34], [36, 8, 8, 0, 0, 58, 0, 26], [0, 9, 0, 74, 0, 83, 55, 49, 28, 28, 0, 0, 49, 0, 49, 0, 0, 63, 0, 0, 68, 83, 55], [14, 8, 74, 0, 63, 45, 0, 72, 0, 66]], 'g3pC': [[0, 17, 17, 17, 36, 0, 19, 0, 19, 53, 26, 49, 0, 19, 0, 45, 9, 14, 26, 0, 32, 32, 32, 63], [36, 0, 42, 45, 45, 45, 45, 0, 0, 67, 67, 69, 33, 26, 0, 9], [0, 69, 69, 0, 45, 0, 72, 72, 83, 0, 58, 58], [34, 8, 74, 69, 0, 8, 0, 69, 0, 72, 72, 72], [35, 65, 65, 0, 69, 0, 72, 0, 69, 65, 54, 75, 28, 28, 0, 73, 28, 0, 28, 9, 9, 69, 69, 69, 0, 0, 73, 0], [36, 0, 119, 119, 119, 0, 119, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 52, 53, 53, 0, 52, 52, 0, 0, 52]], 'g4pB': [[36, 0, 0, 0, 61, 0, 28, 0, 49, 0, 53, 25, 43], [33, 17, 17, 8, 8, 0, 0, 17, 0, 34, 0, 43], [55, 0, 17, 74, 8, 0, 34, 19, 0, 70, 66, 0, 0], [0, 0, 14, 0, 36, 0, 32, 0, 34, 0, 28, 19, 32, 49, 76, 0], [0, 32, 0, 26, 0, 68, 0, 0, 0, 49, 0, 0, 34, 0, 28], [0, 68, 32, 58, 68, 49, 72], [0, 53, 72], [48, 42, 28, 0, 49, 0, 53, 0, 43, 61], [68, 8, 8, 0], [55, 68, 74, 8, 9], [0, 17, 17, 17, 36, 0, 42, 0, 58], [0, 14, 49, 0, 53, 74, 8, 68], [49, 0, 53, 8, 8], [0, 28, 49, 0, 53, 0], [17, 8, 0, 0, 14, 34, 0, 61], [14, 0, 52], [55, 17, 49, 74, 75, 0, 61], [83, 0, 0, 33, 34]], 'g4pC': [[0, 17, 17, 17, 36, 0, 19, 0, 19, 53, 26, 49, 0, 19, 0, 45, 9, 14, 26, 0, 32, 32, 32, 63], [0, 36, 62, 62, 62, 0, 0, 36, 62, 0, 62, 0, 62, 0, 62, 0, 17, 71], [62, 0, 62, 65, 43, 0, 39, 65, 0, 119, 119, 0, 59, 0, 45, 0, 75, 83, 83, 39, 54, 0, 8, 74, 57, 33, 57, 65, 61, 43], [0, 53, 26, 42, 9, 26, 26, 75, 77, 0, 28, 49, 0, 49, 0, 0, 75, 75, 26, 19, 0, 26, 0, 9, 26, 26, 0, 52, 26], [0, 0, 58, 0, 75, 75, 75, 66, 0, 61, 0, 70, 68], [36, 0, 42, 45, 45, 45, 45, 0, 0, 67, 67, 69, 33, 26, 0, 9], [0, 69, 69, 0, 45, 0, 72, 72, 83, 0, 58, 58], [34, 8, 74, 69, 0, 8, 0, 69, 0, 72, 72, 72], [35, 65, 65, 0, 69, 0, 72, 0, 69, 65, 54, 75, 28, 28, 0, 73, 28, 0, 28, 69, 9, 9, 69, 69, 69, 0, 0, 73, 0], [0, 73, 0, 36, 0, 0, 72, 0, 72, 72, 72, 8, 72, 72, 0, 66, 66, 0, 66, 0, 0, 36], [36, 36, 0, 61, 65, 65, 45, 65, 19, 71, 58, 72, 0, 66, 69, 119, 0, 119, 119, 66], [36, 0, 119, 119, 119, 0, 119, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 52, 53, 53, 0, 52, 52, 0, 0, 52], [36, 0, 36, 0, 76, 67, 0, 0, 48, 72, 54, 0, 0, 68, 68, 0]], 'g4pD': [[0, 63, 0, 36, 0, 0, 0, 0, 53, 26, 0, 0, 32, 75, 26], [0, 62, 0, 36, 62, 68, 0, 0], [9, 71, 0, 68, 0, 26, 26, 28, 0, 73, 0, 49, 0, 0, 26, 25, 19, 48, 0, 26], [49, 33, 26, 0, 119, 45, 26, 26, 0, 45, 26, 0, 9, 52, 26], [0, 63, 0, 36, 0, 0, 75, 0, 75, 66, 0, 61, 0, 70, 68, 17, 28], [0, 62, 62, 0, 36, 0, 0, 0, 0, 62, 0, 17, 71], [0, 65, 43, 0, 39, 65, 0, 0, 0, 119, 119, 0, 0, 59, 0, 45, 0, 75, 83, 0, 45, 62], [33, 45, 44, 0, 0, 57, 65, 0, 0, 74, 0, 74, 0, 74, 8, 8], [0, 0, 22, 75, 83, 0, 33, 83, 39, 54, 0, 8, 74, 57, 33, 57, 65, 0, 74], [48, 0, 33, 0, 8, 32, 72, 0, 72, 72], [0, 73, 0, 36, 62, 0, 0, 0, 9, 72, 72, 72, 0, 66, 19, 0, 66, 0, 0, 36]], 'g4pE': [[17, 17, 17, 0, 0, 17, 0, 36, 0, 65], [36, 59, 26, 53, 34, 25, 0, 26, 34], [0, 8, 42, 48, 48, 0, 34, 0, 61, 26, 0, 36], [36, 62, 26, 0], [0, 61, 34, 0, 28, 0, 68, 0, 34, 0, 0, 8, 48, 0, 26, 34, 52, 77, 0, 54, 42, 68, 74, 68], [36, 0, 0, 0, 68, 0, 53, 68, 0, 17, 17, 68, 0, 0, 69, 0, 61, 34, 0, 28, 0, 49, 0, 34, 74, 0, 0, 48, 69, 0, 28, 0, 49, 0, 61, 34, 83, 32, 0, 26, 34, 0, 61, 34], [62, 0, 17, 68, 42, 36, 0, 55, 62, 9, 62, 0, 0, 32, 42, 0, 0, 0, 0, 119, 119], [0, 74, 83, 39, 54, 0, 8, 74], [42, 74, 63, 42, 9, 36], [0, 63, 14, 0, 73, 0, 9, 0, 26], [0, 8, 14, 65, 0, 74, 76, 69, 0, 63, 34, 0, 72, 72, 0, 61, 0, 0, 63, 34, 48, 28, 28, 0, 73, 0, 69, 34]], 'orig': [[0, 17, 17, 17, 36, 0, 19, 0, 19, 53, 26, 49, 0, 19, 0, 45, 9, 14, 26, 0, 32, 32, 32, 63], [0, 36, 62, 62, 62, 0, 0], [0, 53, 26, 42, 9, 26, 26, 75, 77, 0, 28, 49, 0, 49, 0, 0, 75, 75, 26, 19, 0, 26, 0, 9, 26, 26, 0, 52, 26], [0, 0, 58, 0, 75, 75, 75, 66, 0, 61, 0, 70, 68], [36, 62, 0, 62, 0, 62, 0, 62, 0, 17, 71], [62, 0, 62, 65, 43, 0, 39, 65, 0, 119, 119, 0, 59, 0, 45, 63, 0, 42, 57, 57, 65, 0, 74, 0, 74, 46, 74, 8, 8, 0, 75, 83, 83, 39, 54, 0, 8, 74, 57, 33, 57, 65, 61, 43], [36, 0, 42, 45, 45, 45, 45, 0, 0, 67, 67, 69, 33, 26, 0, 9], [0, 69, 69, 0, 45, 0, 72, 72, 83, 0, 58, 58], [34, 8, 74, 69, 0, 8, 0, 69, 0, 72, 72, 72], [35, 65, 65, 0, 69, 0, 72, 0, 69, 65, 54, 75, 28, 28, 0, 73, 28, 0, 28, 69, 9, 9, 69, 69, 69, 0, 0, 73, 0], [0, 73, 0, 36, 0, 0, 72, 0, 72, 72, 72, 8, 72, 72, 0, 66, 66, 0, 66, 0, 0, 36], [36, 36, 0, 61, 65, 65, 45, 65, 19, 71, 58, 72, 0, 66, 69, 119, 0, 119, 119, 66], [36, 0, 119, 119, 119, 0, 119, 119, 34, 0, 52, 53, 52, 0, 52, 0, 0, 52, 53, 53, 0, 52, 52, 0, 0, 52], [36, 0, 36, 0, 76, 67, 0, 0, 48, 72, 54, 0, 0, 68, 68, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# Creating vector of sentences\n",
    "\n",
    "vector_dict = {}\n",
    "for key, value in question_mapping.items():\n",
    "    vector_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        vector_dict[key][student] = []\n",
    "        for sent in answer:\n",
    "            words = sent.split(' ')\n",
    "            temp_list = []\n",
    "            for w in words:\n",
    "                for cluster_key, cluster_value in clust_dict.items():\n",
    "                    if w in clust_dict[cluster_key]:\n",
    "                        temp_list.append( cluster_key)\n",
    "            vector_dict[key][student].append(temp_list)\n",
    "            \n",
    "for k, v in vector_dict.items():\n",
    "    print(k, '    ', v)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_name = {}\n",
    "rep = 0\n",
    "for key, value in vector_dict.items():\n",
    "    for student, vector in value.items():\n",
    "        for v in vector:\n",
    "            vector_name[tuple(v)] = rep\n",
    "            rep+=1\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taska      {'g0pA': [0, 1, 2, 3, 4, 5, 6, 7], 'g0pB': [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], 'g0pC': [20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'g0pD': [30, 31, 32, 33, 34, 220, 36, 222], 'g0pE': [212, 213, 40, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224], 'g1pA': [51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62], 'g1pB': [63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73], 'g1pD': [74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84], 'g2pA': [85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 1065, 96, 97, 98, 99], 'g2pB': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112], 'g2pC': [113, 214, 215, 222, 223, 224, 119, 120, 121, 122], 'g2pE': [123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135], 'g3pA': [136, 137, 138, 139, 140, 141, 142], 'g3pB': [143, 144, 145, 146, 147, 148, 149, 150, 151, 152], 'g3pC': [212, 218, 219, 220, 157, 224], 'g4pB': [159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176], 'g4pC': [212, 178, 179, 214, 215, 218, 219, 220, 221, 222, 223, 224, 225], 'g4pD': [190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200], 'g4pE': [201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211], 'orig': [212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225]}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Creating answer vectors.\n",
    "\n",
    "pro_dict = {}\n",
    "for key, value in vector_dict.items():\n",
    "    pro_dict[key] = {}\n",
    "    for student, answer in value.items():\n",
    "        pro_dict[key][student] = []\n",
    "        for v in answer:\n",
    "            ans = tuple(v)\n",
    "            pro_dict[key][student].append(vector_name[ans])\n",
    "\n",
    "for key, value in pro_dict.items():\n",
    "    print(key, '    ', value)\n",
    "    break\n",
    "    \n",
    "print(len(pro_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfpgrowth\n",
    "inp = [\"taske\", \"taska\", \"taskb\", \"taskc\", \"taskd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing FP_Growth Algorithm\n",
    "\n",
    "def fp_growth(transactions):\n",
    "    patterns = pyfpgrowth.find_frequent_patterns(transactions, 3)\n",
    "    frequent_list = []\n",
    "    for p in patterns:\n",
    "        if len(p) < 3:\n",
    "            continue\n",
    "        else:\n",
    "            frequent_list.append(list(p))\n",
    "    return frequent_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sub(sub, lst):\n",
    "    ln = len(sub)\n",
    "    for i in range(len(lst) - ln + 1):\n",
    "        if all(sub[j] == lst[i+j] for j in range(ln)):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(frequent_list):\n",
    "    output_dict= {}\n",
    "    for lst in frequent_list:\n",
    "        for k, v in pro_dict.items():\n",
    "            for name, vec in v.items():\n",
    "                if is_sub(lst,vec):\n",
    "                    if k not in output_dict:\n",
    "                        output_dict[k] = [name]\n",
    "                    else:\n",
    "                        output_dict[k].append(name)\n",
    "    return output_dict\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Item-sets By the FP-Growth:-\n",
      "[[821, 823, 831], [819, 823, 831], [819, 821, 831], [819, 821, 823, 831], [788, 819, 821], [816, 819, 821], [819, 821, 823]]\n",
      "\n",
      "\n",
      "taske  Copied By-->    {'g1pB', 'orig', 'g0pE', 'g2pB'}\n",
      "taska  Copied By-->    {'g4pC', 'g3pC', 'orig', 'g2pC', 'g0pE'}\n"
     ]
    }
   ],
   "source": [
    "# Final output from our script.\n",
    "\n",
    "final= {}\n",
    "for task in inp:\n",
    "    transactions = []\n",
    "    for k, v in pro_dict.items():\n",
    "        if k == task:\n",
    "            for name, vec in v.items():\n",
    "                transactions.append(vec)\n",
    "            frequent_list = fp_growth(transactions)\n",
    "    output_dict = output(frequent_list)\n",
    "    for key, value in output_dict.items():\n",
    "        final[key] = set(value)\n",
    "print(\"Frequent Item-sets By the FP-Growth:-\")        \n",
    "print(frequent_list)\n",
    "print(\"\\n\")\n",
    "for i, v in final.items():\n",
    "    print(i, ' Copied By-->   ', v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xl = pd.ExcelFile(\"corpus_final.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xl.parse(\"File list\")\n",
    "df1 = xl.parse(\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df[['File','Category']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1pB_taske\n",
      "orig_taske\n",
      "g0pE_taske\n",
      "g2pB_taske\n",
      "g4pC_taska\n",
      "g3pC_taska\n",
      "orig_taska\n",
      "g2pC_taska\n",
      "g0pE_taska\n",
      "6\n",
      "1\n",
      "103\n",
      "61\n",
      "Precision is :  0.8571428571428571\n",
      "Recall is :  0.08955223880597014\n",
      "Accuracy is :  0.6374269005847953\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "tp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "fp = 0\n",
    "for key, value in final.items():\n",
    "    for v in value:\n",
    "        m=v+'_'+key\n",
    "        print(m)\n",
    "        ans = v+key+'.txt'\n",
    "        head = key\n",
    "        for index, row in c.iterrows():\n",
    "            if row['File'].split('_')[1].split('.')[0] == head:\n",
    "                if row['File'].split('_')[0] == v:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        tp+=1\n",
    "                    else:\n",
    "                        fp+=1\n",
    "                else:\n",
    "                    if row['Category'] == 'cut' or row['Category'] == 'heavy':\n",
    "                        fn +=1\n",
    "                    else:\n",
    "                        tn+=1\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(tn)\n",
    "print(fn)\n",
    "precision = float(tp/(tp+fp))                        \n",
    "print('Precision is : ', precision)\n",
    "recall = float(tp/(tp+fn))\n",
    "print('Recall is : ', recall)\n",
    "print('Accuracy is : ', (tp+tn)/(tp+fn+tn+fp))\n",
    "\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[55  2]\n",
      " [26 12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2447a8d1f98>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(df1['Actual'].values, df1['Predicted'].values, classes=[\"Non-Plagirized\",\"Plagarized\"],\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Non-Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Plagarized', 'Non-Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Non-Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Non-Plagarized',\n",
       "       'Plagarized', 'Non-Plagarized', 'Plagarized', 'Non-Plagarized',\n",
       "       'Plagarized', 'Non-Plagarized', 'Non-Plagarized', 'Non-Plagarized',\n",
       "       'Plagarized', 'Non-Plagarized', 'Plagarized', 'Non-Plagarized',\n",
       "       'Plagarized', 'Non-Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Non-Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Plagarized', 'Non-Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Non-Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Non-Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Plagarized', 'Non-Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Non-Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Plagarized', 'Non-Plagarized', 'Non-Plagarized', 'Plagarized',\n",
       "       'Non-Plagarized', 'Non-Plagarized', 'Plagarized', 'Non-Plagarized',\n",
       "       'Non-Plagarized', 'Plagarized', 'Plagarized', 'Non-Plagarized',\n",
       "       'Plagarized', 'Non-Plagarized', 'Non-Plagarized'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in range(len(df1)):\n",
    "#   print(df1.iloc[i:,8:9])\n",
    "df1['Actual'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
